{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a42bca6-aa87-4d61-922f-cb3877d5f635",
   "metadata": {},
   "source": [
    "## A quick tutorial to demonstrate how to access and use Airborne SMCE s3 buckets in Python\n",
    "\n",
    "Note: this is a work in progress and others with more experience should feel free to expand this tutorial\n",
    "\n",
    "**sources:** <br>\n",
    "https://sciwiki.fredhutch.org/compdemos/aws-s3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a993b5d-568e-4a2f-bc43-477bac526acb",
   "metadata": {},
   "source": [
    "### 1. Import libriaries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8789f7-34f2-440c-bbab-85f55a136af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules \n",
    "import os, time, sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import io # for StringIO, BytesIO. or could just be: from io import StringIO, BytesIO\n",
    "# load pandas and dask to demo how to read/write to s3 tabular datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f5ffeb-220e-4731-8029-241b8da80746",
   "metadata": {},
   "source": [
    "### 2. Setup s3 client connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4299d3a9-21b7-40cd-a991-84106307006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SMCE username: sserbin ***\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "# set SMCE username - used later when creating a scratch space on s3\n",
    "user_name = os.popen('whoami').read().strip()\n",
    "print(\"*** SMCE username: \" + user_name + \" ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8b6ac-c0a1-40bc-9398-6c74a21dfd41",
   "metadata": {},
   "source": [
    "### 3. Show all availible buckets\n",
    "\n",
    "List the bucket names instead of displaying all of the metadata.  If you would like to show all the metadata you can use:\n",
    "\n",
    "```print(response)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2add63-733d-49c2-b185-592a7383fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeronet-disaster-backup\n",
      "airborne-data-transfer\n",
      "airborne-pcluster\n",
      "airborne-scratch\n",
      "airborne-smce-dev-state\n",
      "airborne-smce-prod-conda-store-bucket\n",
      "airborne-smce-prod-state\n",
      "airborne-smce-prod-user-bucket\n",
      "config-bucket-445567107118\n",
      "config-bucket-smce-445567107118\n",
      "cur-reports-smce-445567107118\n",
      "gliht\n",
      "gliht-processed\n",
      "gliht-raw\n",
      "isofit-data\n",
      "parallelcluster-0895790225836e61-v1-do-not-delete\n",
      "parallelcluster-3cbb946982171420-v1-do-not-delete\n",
      "smdc-prod-ap-southeast-2-445567107118-obs-outbound-bucket\n",
      "smdc-prod-eu-north-1-445567107118-obs-outbound-bucket\n",
      "smdc-prod-me-south-1-445567107118-obs-outbound-bucket\n",
      "smdc-prod-us-east-1-445567107118-obs-outbound-bucket\n",
      "smdc-prod-us-east-2-445567107118-obs-outbound-bucket\n",
      "smdc-prod-us-west-1-445567107118-obs-outbound-bucket\n",
      "smdc-prod-us-west-2-445567107118-obs-outbound-bucket\n",
      "uas-data-storage\n",
      "whymsie\n",
      "whymsie-processed\n",
      "whymsie-raw\n"
     ]
    }
   ],
   "source": [
    "response = s3.list_buckets() # show all buckets\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053af43-0581-4537-bc94-563da53dcd4e",
   "metadata": {},
   "source": [
    "### 3. Define an s3 bucket you want to work with and list the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5b57dd-af15-47c8-91f6-42e5327a4a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sserbin/dummy_csv_s3.csv\n",
      "aist21/Matlab_data_format.zip\n",
      "aist21/gliht/bnl2016/Brookhaven_Jun2016_mosaicked_refl_VIs.tar.gz\n",
      "dask_data_parts/0.part\n",
      "dask_data_parts/1.part\n",
      "dask_data_parts/2.part\n",
      "edlang/.ipynb_checkpoints/untitled-checkpoint.txt\n",
      "edlang/.~test.txt\n",
      "edlang/.~untitled.txt\n",
      "edlang/test.txt\n",
      "hyrsense_data/hyrsense.tar.gz\n",
      "nquinteros/.ipynb_checkpoints/test-checkpoint.txt\n",
      "nquinteros/.~test.txt\n",
      "nquinteros/.~untitled.txt\n",
      "nquinteros/test.txt\n",
      "scratch/user1/test2.txt\n",
      "sserbin/.ipynb_checkpoints/test-checkpoint.txt\n",
      "sserbin/.test.txt.swp\n",
      "sserbin/.test.txt.swx\n",
      "sserbin/.~test.txt\n",
      "sserbin/test.txt\n",
      "tutorial_data/aiml_tutorials/aqi/AirQualityUCI.csv\n",
      "tutorial_data/aiml_tutorials/aqi/AirQualityUCI.xlsx\n",
      "tutorial_data/hyrsense/hyrsense.tar.gz\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"airborne-smce-prod-user-bucket\" # substitute your actual bucket name\n",
    "\n",
    "# List objects in a bucket\n",
    "bucket_ls = s3.list_objects_v2(Bucket=bucket_name)\n",
    "for item in bucket_ls['Contents']:\n",
    "    print(item['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa265e42-ce9d-4be2-b3ee-1c23f0dabce1",
   "metadata": {},
   "source": [
    "### 4. Read some data from s3. For this we will source data from the an AI/ML tutorial csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5261aa-f184-4e70-8d60-ac6c7243c99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  10/03/2004  18.00.00     2.6       1360.0     150.0      11.9   \n",
       "1  10/03/2004  19.00.00     2.0       1292.0     112.0       9.4   \n",
       "2  10/03/2004  20.00.00     2.2       1402.0      88.0       9.0   \n",
       "3  10/03/2004  21.00.00     2.2       1376.0      80.0       9.2   \n",
       "4  10/03/2004  22.00.00     1.6       1272.0      51.0       6.5   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0         1046.0    166.0        1056.0    113.0        1692.0       1268.0   \n",
       "1          955.0    103.0        1174.0     92.0        1559.0        972.0   \n",
       "2          939.0    131.0        1140.0    114.0        1555.0       1074.0   \n",
       "3          948.0    172.0        1092.0    122.0        1584.0       1203.0   \n",
       "4          836.0    131.0        1205.0    116.0        1490.0       1110.0   \n",
       "\n",
       "      T    RH      AH  Unnamed: 15  Unnamed: 16  \n",
       "0  13.6  48.9  0.7578          NaN          NaN  \n",
       "1  13.3  47.7  0.7255          NaN          NaN  \n",
       "2  11.9  54.0  0.7502          NaN          NaN  \n",
       "3  11.0  60.0  0.7867          NaN          NaN  \n",
       "4  11.2  59.6  0.7888          NaN          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the connection to the csv file stored on s3\n",
    "csv_filename = 'AirQualityUCI.csv'\n",
    "csv_file_path = 'tutorial_data/aiml_tutorials/aqi/'\n",
    "csv_file = s3.get_object(Bucket=bucket_name, Key=os.path.join(csv_file_path,csv_filename))\n",
    "#print(csv_file)\n",
    "\n",
    "# Now read the data into a Pandas dataframe\n",
    "df = pd.read_csv(io.BytesIO(csv_file['Body'].read()), sep=';', decimal=',')\n",
    "df.head()\n",
    "\n",
    "# Finally display the data below confirming you have read in the data from s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3b2a0-be10-48db-91d8-98367cd6311e",
   "metadata": {},
   "source": [
    "### 5. Write data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7688e64e-2fa9-42fc-bc16-6ff2db62c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  34  10  85  24\n",
       "1  38  79  24  70\n",
       "2  68  35  15  64\n",
       "3  54  74  20  49\n",
       "4  54  29   2   4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a pandas data frame of random numbers:\n",
    "df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acbc853-289c-41b4-b41d-7ecf4d7bd52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>79</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  34  10  85  24\n",
       "1  38  79  24  70\n",
       "2  68  35  15  64\n",
       "3  54  74  20  49\n",
       "4  54  29   2   4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First set s3 location and file name of the csv file\n",
    "bucket_name = bucket_name # same bucket name from above\n",
    "#print(bucket_name)\n",
    "s3_object_key = os.path.join('scratch',user_name,'dummy_csv_s3.csv') # this defines the full path\n",
    "#print(s3_object_key)\n",
    "\n",
    "# Create the csv file from memory\n",
    "csv_buffer = io.StringIO()\n",
    "#print(csv_buffer)\n",
    "df.to_csv(csv_buffer, index=False) # Write DataFrame to CSV string in buffer. Drop the index column\n",
    "#df.to_csv(csv_buffer) # Write DataFrame to CSV string in buffer\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24925b7-e83e-4a21-a94d-81d32ad88480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,B,C,D\n",
      "34,10,85,24\n",
      "38,79,24,70\n",
      "68,35,15,64\n",
      "54,74,20,49\n",
      "54,29,2,4\n",
      "27,15,0,9\n",
      "83,73,98,66\n",
      "86,67,46,9\n",
      "2,96,63,86\n",
      "64,53,37,17\n",
      "8,62,18,59\n",
      "2,82,74,35\n",
      "89,61,8,68\n",
      "63,17,3,0\n",
      "61,44,40,80\n",
      "31,37,68,47\n",
      "81,70,81,17\n",
      "98,77,78,67\n",
      "39,63,63,70\n",
      "59,13,9,40\n",
      "30,37,61,19\n",
      "22,20,17,1\n",
      "29,46,99,35\n",
      "67,54,51,20\n",
      "65,44,87,72\n",
      "65,87,92,28\n",
      "9,57,23,54\n",
      "21,56,15,41\n",
      "0,82,99,10\n",
      "82,54,18,54\n",
      "32,76,79,45\n",
      "3,37,10,18\n",
      "27,48,73,72\n",
      "61,88,90,85\n",
      "3,81,85,89\n",
      "80,77,57,62\n",
      "47,17,54,65\n",
      "18,59,0,46\n",
      "28,99,93,92\n",
      "42,37,14,46\n",
      "66,66,22,10\n",
      "21,32,19,59\n",
      "84,87,1,1\n",
      "43,69,8,43\n",
      "88,1,35,73\n",
      "89,36,87,51\n",
      "84,20,70,68\n",
      "85,65,72,98\n",
      "39,54,47,50\n",
      "82,32,10,76\n",
      "93,73,66,34\n",
      "5,25,20,97\n",
      "91,39,35,86\n",
      "59,85,28,65\n",
      "28,73,94,9\n",
      "36,91,55,1\n",
      "74,25,12,20\n",
      "96,50,66,82\n",
      "4,41,67,45\n",
      "78,42,15,32\n",
      "9,54,13,55\n",
      "71,3,11,78\n",
      "80,87,37,38\n",
      "12,14,24,25\n",
      "31,42,63,97\n",
      "94,72,0,59\n",
      "36,91,30,51\n",
      "14,20,96,29\n",
      "74,81,5,80\n",
      "56,76,18,70\n",
      "9,84,25,92\n",
      "80,40,31,67\n",
      "4,73,39,80\n",
      "38,62,37,40\n",
      "55,84,19,35\n",
      "90,20,56,88\n",
      "79,21,93,30\n",
      "0,88,57,86\n",
      "60,68,77,57\n",
      "80,21,42,26\n",
      "72,73,66,89\n",
      "64,65,36,26\n",
      "51,95,96,49\n",
      "45,90,21,71\n",
      "88,52,58,97\n",
      "95,2,63,37\n",
      "50,92,40,40\n",
      "55,32,45,77\n",
      "42,28,41,4\n",
      "71,57,60,23\n",
      "83,52,48,1\n",
      "30,22,4,27\n",
      "60,41,21,88\n",
      "71,45,16,53\n",
      "54,52,79,69\n",
      "45,70,0,14\n",
      "50,63,82,4\n",
      "71,99,4,24\n",
      "17,20,4,97\n",
      "96,92,68,14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the csv_buffer\n",
    "print(csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeec28d7-e72b-4da6-8ced-2b977fe21548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote data to 's3://airborne-smce-prod-user-bucket/scratch/sserbin/dummy_csv_s3.csv'\n"
     ]
    }
   ],
   "source": [
    "### save it in s3:\n",
    "#s3_object = s3_resource.Object(bucket_name, s3_object_key)\n",
    "#print(s3_object)\n",
    "s3_resource.Object(bucket_name, s3_object_key).put(Body=csv_buffer.getvalue())\n",
    "print(f\"Successfully wrote data to 's3://{bucket_name}/{s3_object_key}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b81088cb-eb46-439c-8a52-ddc8d51c04bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://{}/scratch/sserbin/dask_data_parts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airborne-smce-prod-user-bucket/scratch/sserbin/dask_data_parts/0.part',\n",
       " 'airborne-smce-prod-user-bucket/scratch/sserbin/dask_data_parts/1.part',\n",
       " 'airborne-smce-prod-user-bucket/scratch/sserbin/dask_data_parts/2.part']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert data frame to dask:\n",
    "dask_df = dd.from_pandas(df, 3)\n",
    "\n",
    "# save dask data frame to s3 in parts:\n",
    "save_dask_loc = os.path.join('s3://{}/','scratch',user_name,'dask_data_parts')\n",
    "print(save_dask_loc)\n",
    "dask_df.to_csv(save_dask_loc.format(bucket_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfcb10-dfcb-4351-bc9d-a91ed5a5a999",
   "metadata": {},
   "source": [
    "### 6. Read dask from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dcae150-759a-47a4-bbf9-0973ddf0b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://{}/scratch/sserbin/dask_data_parts/*\n"
     ]
    }
   ],
   "source": [
    "# We will create a dask df using the dask dataframe you just saved on the scratch space on s3\n",
    "save_dask_loc = os.path.join('s3://{}/','scratch',user_name,'dask_data_parts','*')\n",
    "print(save_dask_loc)\n",
    "dask_df2 = dd.read_csv(\"s3://{}/dask_data_parts/*\".format(bucket_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0abe6d1-ae71-44ca-a361-b049f764df4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>91</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>87</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   A   B   C   D\n",
       "0           0  97  91  18  17\n",
       "1           1  51  87  32  50\n",
       "2           2   0  49  38  90\n",
       "3           3  99  32  39  39\n",
       "4           4  72  18  40  10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now display the new datagframe\n",
    "dask_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fba2758-e0f1-4b6c-a313-087282921a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask DataFrame Structure:\n",
      "              Unnamed: 0      A      B      C      D\n",
      "npartitions=3                                       \n",
      "                   int64  int64  int64  int64  int64\n",
      "                     ...    ...    ...    ...    ...\n",
      "                     ...    ...    ...    ...    ...\n",
      "                     ...    ...    ...    ...    ...\n",
      "Dask Name: to_string_dtype, 2 expressions\n",
      "Expr=ArrowStringConversion(frame=FromMapProjectable(24cae9e))\n"
     ]
    }
   ],
   "source": [
    "print(dask_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29cfed-700c-4202-83ad-7c1b1f79274a",
   "metadata": {},
   "source": [
    "### 7. Upload a file to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fa30d76-51cc-4ed8-837d-5cd7ff4b632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch/sserbin/dummy_csv_s3_local.csv\n",
      "Successfully wrote data to 's3://airborne-smce-prod-user-bucket/scratch/sserbin/dummy_csv_s3_local.csv'\n"
     ]
    }
   ],
   "source": [
    "# write the example data frame to a local file. We will use our local tutorial folder and make a file in scratch space\n",
    "tutorials_scratch = os.path.join(os.path.expanduser(\"~\"),\"tutorials\",\"scratch\")\n",
    "if not os.path.exists(tutorials_scratch):\n",
    "    dest_dir_path = Path(tutorials_scratch)\n",
    "    dest_dir_path.mkdir(parents=True, mode=0o777, exist_ok=True) # create the directory for the copied data, if needed\n",
    "\n",
    "# convert the existing df to a csv file and store locally\n",
    "filename_csv = os.path.join(tutorials_scratch,'dummy_csv_s3_local.csv')\n",
    "df.to_csv(filename_csv, index=False)\n",
    "\n",
    "# upload file to s3 from local storage:\n",
    "s3_object_key = os.path.join('scratch',user_name,'dummy_csv_s3_local.csv') # this defines the full path\n",
    "print(s3_object_key)\n",
    "s3.upload_file(Filename=filename_csv, Bucket=bucket_name, Key=s3_object_key)\n",
    "#s3.upload_file(local_file_path, bucket_name, s3_key)\n",
    "\n",
    "print(f\"Successfully wrote data to 's3://{bucket_name}/{s3_object_key}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3d4ed-3c33-436d-bb34-bb5629ab7b83",
   "metadata": {},
   "source": [
    "### 8. Download a file from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32e20958-f775-4778-a2cd-d71cf662b1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second argument is the remote name/key, third argument is local name\n",
    "filename_csv = os.path.join(tutorials_scratch,'dummy_csv_s3_local_s3.csv')\n",
    "s3.download_file(bucket_name, s3_object_key, filename_csv)\n",
    "#s3.download_file(Bucket, Key, Filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9abfc3-6285-4cd9-a890-5107e53aa4d5",
   "metadata": {},
   "source": [
    "### 9. Write data to s3 using a custom s3 upload function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050ae738-3c4f-4187-a8d8-1ef8da6a87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_s3_folder(file_path, bucket_name, folder_name, s3_file_name):\n",
    "    \"\"\"\n",
    "    Uploads a file to a specified \"folder\" within an S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The local path to the file you want to upload.\n",
    "        bucket_name (str): The name of your S3 bucket.\n",
    "        folder_name (str): The name of the \"folder\" within the S3 bucket.\n",
    "        s3_file_name (str): The desired name of the file in S3.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Construct the full S3 key (object name) including the folder prefix\n",
    "    s3_key = f\"{folder_name}/{s3_file_name}\"\n",
    "\n",
    "    try:\n",
    "        s3.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"Successfully uploaded '{file_path}' to s3://{bucket_name}/{s3_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8db05d12-7eb0-4022-9344-1dbadc53b2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded '/home/jovyan/tutorials/scratch/dummy_csv_s3_local_s3.csv' to s3://airborne-smce-prod-user-bucket/scratch/sserbin/file_upload/dummy_csv_s3_upload.csv\n"
     ]
    }
   ],
   "source": [
    "## Use the existing demo files and paths for this example\n",
    "# Example usage:\n",
    "#local_file = 'my_local_file.txt'  # Replace with your local file path\n",
    "#s3_bucket = 'your-s3-bucket-name'  # Replace with your S3 bucket name\n",
    "#s3_folder = 'new_data_folder'  # The \"new folder\" name\n",
    "#s3_object_name = 'uploaded_document.txt'  # The name of the file in S3\n",
    "\n",
    "local_file = filename_csv\n",
    "s3_bucket = bucket_name\n",
    "s3_folder = os.path.join('scratch',user_name,'file_upload')\n",
    "s3_object_name = 'dummy_csv_s3_upload.csv'  # The name of the file in S3\n",
    "\n",
    "# upload the file using the function\n",
    "upload_file_to_s3_folder(local_file, s3_bucket, s3_folder, s3_object_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1211e-5450-4624-9993-e4fbfe06be6d",
   "metadata": {},
   "source": [
    "### 10. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bae6d-0a54-47fa-a15d-39305280badf",
   "metadata": {},
   "source": [
    "**Start with the s3 temporary files and folder**\n",
    "\n",
    "\n",
    "NOTE: Deleting entire directories on s3 isnt as straightforward as a traditional file system. However we can create a simple function to do this be leveraing boto3 fuctions and using s3 object keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1bbb011-6be6-403b-b883-d9c7a7246524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define delete function. This function assumes you want to delete the entire contents of the folder provided as an argument to the function\n",
    "def delete_s3_folder_recursive(bucket_name, folder_prefix):\n",
    "    \"\"\"\n",
    "    Deletes all objects within a specified \"folder\" (prefix) in an S3 bucket.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket.\n",
    "        folder_prefix (str): The prefix representing the \"folder\" to delete.\n",
    "                             Ensure it ends with a '/' if you want to target\n",
    "                             a specific directory.\n",
    "    \"\"\"\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "    # List all objects with the given prefix\n",
    "    objects_to_delete = []\n",
    "    for obj in bucket.objects.filter(Prefix=folder_prefix):\n",
    "        objects_to_delete.append({'Key': obj.key})\n",
    "\n",
    "    # If there are objects to delete, perform the deletion\n",
    "    if objects_to_delete:\n",
    "        try:\n",
    "            response = bucket.delete_objects(\n",
    "                Delete={\n",
    "                    'Objects': objects_to_delete,\n",
    "                    'Quiet': True  # Set to False for verbose output\n",
    "                }\n",
    "            )\n",
    "            print(f\"Deleted objects from '{folder_prefix}' in bucket '{bucket_name}':\")\n",
    "            # You can inspect 'response' for details if 'Quiet' is False\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting objects: {e}\")\n",
    "    else:\n",
    "        print(f\"No objects found with prefix '{folder_prefix}' in bucket '{bucket_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5958836-6107-445f-bd1e-6ceab84ddb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Deleting: scratch/sserbin\n",
      "Deleted objects from 'scratch/sserbin' in bucket 'airborne-smce-prod-user-bucket':\n"
     ]
    }
   ],
   "source": [
    "# Target folder to remove\n",
    "s3_folder = os.path.join('scratch',user_name)\n",
    "print(\"*** Deleting: \" + s3_folder)\n",
    "# Set the target s3 bucket\n",
    "s3_bucket = bucket_name # from above\n",
    "# Delete the folder on s3\n",
    "delete_s3_folder_recursive(s3_bucket, s3_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60051c2-40cd-435a-a33a-e5b245b1fbc4",
   "metadata": {},
   "source": [
    "**Now delete your local scratch space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b563068-3f0b-4753-8df3-229c80b21526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/home/jovyan/tutorials/scratch' and its contents deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Delete local scratch: tutorials_scratch\n",
    "try:\n",
    "    shutil.rmtree(tutorials_scratch)\n",
    "    print(f\"Directory '{tutorials_scratch}' and its contents deleted successfully.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error deleting directory '{tutorials_scratch}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb8c922e-bfee-4532-af4b-06fb84f4cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:global-global-airborne-core]",
   "language": "python",
   "name": "conda-env-global-global-airborne-core-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
